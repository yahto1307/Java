# Kafka配置信息
1. 基本配置
	1.  broker.id:
	> 每个 broker 都需要有**一个标识符**，使用 broker.id 来表示。它的默认值是 0，也可以被设置成其他任意整数。**这个值在整个 kafka 集群里必须是唯一的**。这个值可以任意选定，如果出于维护的需要，可以在服务器节点间交换使用这些id。建议把它们设置成与机器名具有相关性的整数，这样在进行维护时，将 id号映射到机器名就没那么麻烦了。例如，如果机器名包含唯一性的数字（比如host1.example.com、host2.example.com），那么用这些数字来设置broker.id就再好不过了。
	2. port
	> 如果使用配置样本来启动 Kafka，它会监听**9092**端口。修改port配置参数可以把它设置成其他任意可用的端口。要注意，如果使用1024以下的端口，需要使用root权限启动Kafka，不过不建议这么做。
	3. zookeeper.connect
	> 用于保存 broker 元数据的Zookeeper地址是通过zookeeper.connect来指定的。localhost:2181表示这个Zookeeper是运行在本地的2181端口上。该配置参数是用冒号分隔的一组 **hostname:port/path** 列表，每一部分的含义如下：
	• hostname 是 Zookeeper 服务器的机器名或 IP 地址；
	• port 是 Zookeeper 的客户端连接端口；
	• **/path** 是可选的 Zookeeper 路径，作为 Kafka 集群的 chroot 环境。如果不指定，默认使用根路径。
	如果指定的 chroot 路径不存在，broker 会在启动的时候创建它。
	**在 Kafka 集群里使用 chroot 路径是一种最佳实践。Zookeeper 群组可以共享给其他应用程序，即使还有其他 Kafka 集群存在，也不会产生冲突。最好是在配置文件里指定一组 Zookeeper 服务器，用分号把它们隔开。一旦有一个Zookeeper 服务器宕机，broker 可以连接到 Zookeeper 群组的另一个节点上。**
	4. log.dirs
	> Kafka 把所有消息都保存在磁盘上，存放这些日志片段的目录是通过 log.dirs 指定的。**它是一组用逗号分隔的本地文件系统路径**。如果指定了多个路径，那么 broker 会根据“**最少使用**”原则，把同一个分区的日志片段保存到同一个路径下。要注意，**broker 会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。**
	5. num.recovery.threads.per.data.dir
	> 对于如下 3 种情况，Kafka 会使用可配置的线程池来处理日志片段：
	• 服务器正常启动，用于打开每个分区的日志片段；
	• 服务器崩溃后重启，用于检查和截短每个分区的日志片段；
	• 服务器正常关闭，用于关闭日志片段。
	**默认情况下，每个日志目录只使用一个线程。**因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程来达到并行操作的目的。特别是对于包含大量分区的服务器来说，一旦发生崩溃，在进行恢复时使用并行操作可能会省下数小时的时间。**设置此参数时需要注意，所配置的数字对应的是log.dirs指定的单个日志目录。也就是说，如果num.recovery.threads.per.data.dir 被设为 8，并且 log.dir 指定了 3 个路径，那么总共需要 24 个线程。**
	6. auto.create.topics.enable
	> 默认情况下，Kafka 会在如下几种情形下自动创建主题：
	• 当一个生产者开始往主题写入消息时；
	• 当一个消费者开始从主题读取消息时；
	• 当任意一个客户端向主题发送元数据请求时。
	很多时候，这些行为都是非预期的。而且，根据 Kafka 协议，如果一个主题不先被创建，根本无法知道它是否已经存在。如果显式地创建主题，不管是手动创建还是通过其他配置系统来创建，都可以把 auto.create.topics.enable 设为 false。
2. 主题(topic)配置
	1. num.partitions
	> num.partitions 参数指定了新创建的主题将包含多少个分区。如果启用了主题自动创建功能（该功能默认是启用的），主题分区的个数就是该参数指定的值。**该参数的默认值是1**。要注意，**我们可以增加主题分区的个数，但不能减少分区的个数**。**所以，如果要让一个主题的分区个数少于num.partitions指定的值，需要手动创建该主题。**
	2. log.retention.ms
	>. Kafka通常根据时间来决定数据可以被保留多久。**默认使用log.retention.hours参数来配置时间，默认值为168小时，也就是一周。**除此以外，还有其他两个参数log.retention.minutes和log.retention.ms。这3个参数的作用是一样的，都是决定消息多久以后会被删除，不过还是推荐使用log.retention.ms。**如果指定了不止一个参数，Kafka 会优先使用具有最小值的那个参数。**
	3.  log.retention.bytes
	> 是通过保留的消息字节数来判断消息是否过期。它的值通过参数 log.retention.bytes 来指定，作用在每一个分区上。**也就是说，如果有一个包含 8 个分区的主题，并且 log.retention.bytes 被设为 1GB，那么这个主题最多可以保留 8GB 的数据。**所以，当主题的分区个数增加时，整个主题可以保留的数据也随之增加。
	4.  log.segment.bytes
	> 以上的设置都作用在日志片段上，而不是作用在单个消息上。当消息到达broker时，它们被追加到分区的当前日志片段上。**当日志片段大小达到log.segment.bytes 指定的上限（默认是 1GB）时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。**例如，如果一个主题每天只接收100MB的消息，而log.segment.bytes使用默认设置，那么需要10天时间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果 log.retention.ms 被设为 604 800 000（也就是 1 周），那么日志片段最多需要 17 天才会过期。这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时间（要等到日志片段里的最后一个消息过期才能被删除）。
	5. log.segment.ms
	> 另一个可以控制日志片段关闭时间的参数是 log.segment.ms，它指定了多长时间之后日志片段会被关闭。就像 log.retention.bytes 和 log.retention.ms 这两个参数一样log.segment.bytes 和 log.retention.ms 这两个参数之间也不存在互斥问题。日志片段会在大小或时间达到上限时被关闭，就看哪个条件先得到满足。**默认情况下，log.segment.ms 没有设定值，所以只根据大小来关闭日志片段。**
	6.  message.max.bytes
	> broker 通过设置 message.max.bytes 参数来限制**单个消息的大小，默认值是 1 000 000，也就是 1MB。**如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到broker 返回的错误信息。跟其他与字节相关的配置参数一样，该参数指的是压缩后的消息大小，也就是说，只要压缩后的消息小于 message.max.bytes 指定的值，消息的实际大小可以远大于这个值。这个值对性能有显著的影响。**值越大，那么负责处理网络连接和请求的线程就需要花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。**